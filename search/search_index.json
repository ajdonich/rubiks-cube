{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"My Search for a Novel Algorithmic Solution to Rubik\u2019s Cube This repository contains a collection of Python classes and notebooks for exploring algorithmic solutions to Rubik\u2019s cube. I began the project to experiment with Deep Reinforcement Learning, but I think my most interesting results came from abstracted notions of entropy and periodicity applied to the cube. I originally considered a sliding puzzle for the project, but then opted for Rubik\u2019s cube for some added challenge, which it certainly delivered. After six months of diligent effort, I am yet to develop a novel method that can fully crack it, not to mention that I often felt a sense that a solution was just around the corner, making the puzzle as fun as it was vexing. This article describes the solution strategies and results I've traversed thus far (chronologically, despite some arguably ill-conceived, hindsight is 20/20, directions). For discussion of the actual class implementations in the repository, especially those that represent and display the cube (i.e. models and views), please navigate to the Code Docs article. Strategy #1: Neural Networks (NN) and Deep Reinforcement Learning (DRL) For Demo see Notebook 2: Neural Networks My initial direction for solving the cube was to emulate a DRL strategy akin to that developed by DeepMind with its AlphaGo 1 program. This same essential strategy is also described by a group out of UC Irvine in their paper, Solving the Rubik\u2019s Cube Without Human Knowledge. 2 The strategy gist is to combine a NN with a Monte Carlo Tree Search (MCTS), with implementations varying in NN architecture, training methodology, specifics of tree expansion/rollout, etc. Though I eventually made extensive and (moderately) effective use of the tree search, I quickly realized that conventional DRL/RL is not ideally suited for Rubik\u2019s cube because it, RL, depends on initially random moves to produce enough successful outcomes for learning to begin. But unfortunately, a 3x3 cube has 43 quintillion (10^18) possible permutations and one solution. 3 Ever solving it with initially random moves is highly improbable to say the least. This led me to pursue training a NN independently, potentially to drop into DRL afterword, but primarily just to evaluate whether a viable statistical relationship between cube permutations and solution sequences could be established. To generate a training and validation dataset, I used the fact that a valid solution sequence to a cube can be obtained by simply reversing the moves used to scramble it, and if the scramble involves 20 or fewer (non-redundant) moves, one can also probably safely assume the solution is relatively efficient. 4 But despite experimenting with a variety of NN architectures and formats for NN input (for example calculating and using certain vector relationships between cube-facelets 5 as input rather than using straight facelet positions), I was unable to train a network that generalized beyond approx. 20% accuracy to a validation set (as depicted in graphs below). I could overfit training data to ~60% accuracy and suspected such network \u2018memorization\u2019 could continue with a large enough network, which, if inserted into DRL, could theoretically solve cubes whenever the tree-search found a memorized permutation. I\u2019m not clear whether learning could take hold from there, but regardless, I did not continue with that exploration 6 given my limiting computing power to train a very large network. Figure 1: The unfortunately dismal training results using Dance Heuristic inputs into a 5-layer, full-connected policy network Strategy #2: Heuristic-Guided, Upper-Confidence-Bound (UCB) Tree Search For Demo see Notebook 1: Intro-Cube-View My next effort was dedicated to honing a UCB tree search. 7 I began by developing a heuristic function I called Minimum-Distance-Home (see Figure 2 below). A characteristic of the cube is that any given facelet can, independently, be returned to its solved position in at most 2 moves if it is a corner facelet, or 3 moves if it is an edge. The overall heuristic then, is the sum over all facelets of this number-of-moves-to-solved (i.e. 0, 1, 2 or 3) for a given cube permutation. 8 On the positive side, I was fairly happy with the performance of my UCB tree search after optimizing my cube class representation to be based almost entirely on NumPy arrays and matrix operations. Still, the size of the search space was too much. Though I was usually able to solve cubes scrambled out 5-6 moves, beyond that the failure rates spiked. Figure 2: Still from Minimum-Distance-Home (MDH) animation (click to watch video ). Depicts the MDH heuristic as cubes are scrambled and solved/reverse-scrambled. The three rings of the target shaped diagram represent the number (0 to 3) of moves a facelet requires to return to its home/solved position (the center of the target representing home/solved) The 18 spokes represent possible cube moves (in Half-Turn-Metric, notated by face-color and rotation-angle) The small, colored, numbered circles represent the facelets themselves, and the thicker lines represent viable move sequences/trajectories each facelet could traverse to return home 9 Strategy #3: Fridrich\u2019s (CFOP) Human Speedcubing Algorithm For Demo see Notebook 3: CFOP Algorithm I focused my efforts next on integrating human-understanding/strategy into a machine-learning algorithm. 10 The most popular speedcubing method: CFOP, solves the cube in four, layer-based steps, specifically: 1) the Cross, 2) the First 2 Layers, 3) Orient the Last Layer, and 4) Permute the Last Layer. 11 Thus, an obvious approach seemed to be to develop a solver that mimicked a human speedcuber and then use it to generate a training dataset for each step. 12 There are approximately 80, explicitly defined move sequences for the final OLL and PLL steps; challenging for a human to memorize, but essentially trivial to apply in software. The Cross and F2L steps, however, are not as strictly defined, leading me to adapt my tree search to handle them. After a few weeks of work, I finally succeed in algorithmically solving my first cube! Unfortunately, even searching just through the F2L solution was surprisingly complex. Typically search trees would contain 5-15 million nodes, 40-45% of which would be visited. Searches would usually converge in 7-15 (at times up to 20) minutes to solutions that involved 50-70 moves, though some cubes would fail. The large convergence time required per cube thwarted my hopes of ever generating an adequately sized training dataset in a reasonable time frame. Furthermore, the code started to become fairly convoluted and the entire solving strategy piecemeal, in my opinion, as I added the many layers of human-like solving logic necessary to facilitate convergence. Figure 3: Example output of CFOP algorithm solving last few moves of an F2L stage Strategy #4: Entropy, Sequence Periodicity and Dancing Facelets For Demo see Notebook 4: Cycles and Entropy Unsatisfied with my piecemeal solution thus far and, coincidentally, studying the writings of theoretical physicist, David Bohm, particularly concerning distinctions between creative versus mechanistic modes, I began to develop some tangential experiments and visualizations of the cube. These included creating some atypical video animations of the cube as it was scrambled and then solved and examining a cube\u2019s fundamental periodic/repeatable move sequences. 13 Figure 4: Graph of rotational periods for the first 160 fundamental two-sided rotation sequences I noticed in an animation, in contrast to human strategies, highly efficient solutions rarely move facelets to their solved/home positions, right up until the last few moves, when suddenly the whole cube clicks together. This inspired me to create an \u201cEntropy/Order\u201d heuristic intended to measure a kind of entropy or level of order/disorder of a cube permutation. I awarded 1 point to any solution-pair of facelets 14 that achieved a side-by-side orientation, regardless of where that occurred on the overall surface of the cube, then summed this reward across all facelets. 15 As I worked to integrate these new ideas into my tree search, I was surprised to find almost by accident, a short segment of test code was nearly solving the cube by itself. It simply iterated through periodic move sequences and maximized the Order heuristic. I explored this direction further, developing a more sophisticated heuristic I called Dancing Facelets. 16 It could collapse to the Order heuristic if so configured or could measure more nuanced relationships between facelets such as angular measurements or triad relationships. I continued to explore methods of integrating these new components into my tree search or progress with them independently. And I continued to \u201cnearly\u201d solve the cube, but evidently appearances are deceiving with Rubik\u2019s cube; my attempts were clearly converging to local minimums and it wasn\u2019t entirely clear how close or far away true solutions remained. Thus, despite some intriguing results, I\u2019m still at least one more step from victory. Touch\u00e9, Mr. Rubik. Footnotes: 1 See: https://deepmind.com/blog/article/alphago-zero-starting-scratch 2 See: https://arxiv.org/abs/1805.07470. Though the UC Irvine group arrived at a successful implementation and created an online simulator to demonstrate it (see: http://deepcube.igb.uci.edu/), to my knowledge, they have not released their code base and individuals who have tried to replicate their results thus far have been unsuccessful. 3 Despite the colossal size of the permutation space, the maximum possible moves necessary to solve a cube from any position, known as God\u2019s number, is only 20 moves using the Half-Turn-Metric (HTM, i.e. a 180-degree turn counted as one move), or 26 moves using the Quarter-Turn-Metric (QTM) (see: https://www.cube20.org/). Note this also implies that any possible cube permutation is theoretically reachable within a 20-move scramble. 4 From what I can ascertain, this is essentially what the UC Irvine group did as well, though their description is mathematically and pictorially complicated enough that I must admit some confusion in this regard. 5 I use the moniker: facelet, to indicate any of the 54 individual, colored squares that comprise the 3x3 cube, or more specifically the cube is comprised of 6 center facelets, 24 corner facelets, and 24 edge facelets. 6 This strategy seemed kind of like bastardizing a reduction algorithm (see: Thistlethwaite's Algorithm that permutes a cube through smaller, exhaustively searchable subgroups), and then hopefully leveraging that into learning with DRL. 7 Implemented essentially as a Monte Carlo Tree Search, minus the random (\u201cMonte Carlo\u201d) rollout step, removed largely due to the improbability of random moves ever achieving a solution state. 8 I eventually abandoned the Minimum-Distance-Home heuristic after recognizing that it becomes less reliable as a cube becomes more scrambled, w/coefficient of variation (CV) nearly 350% across cubes scrambled 25 moves. 9 Animation developed with Python open source package: Manim, developed by Grant Sanderson for his YouTube mathematics education channel. See: https://github.com/3b1b/manim 10 Driven by a desire to explore the third wave, Contextual Model Adaptation, of DARPA\u2019s Three-Wave theory of AI, specifically: 1) Handcrafted Knowledge, 2) Statistical Learning, 3) Context Adaptation. See: https://youtu.be/DARPA_AI_Perspective 11 For a more detailed description of CFOP, see: http://www.rubiksplace.com/speedcubing/guide/ 12 I knew getting this plan to generalize well may be tricky, having already established the cube\u2019s resistance to a typical NN training approach, nevertheless, I was essentially stumped and needed to turn some gears somehow. 13 Another interesting characteristic of Rubik\u2019s cube is its wave-like periodicity, meaning that any repetitive sequence of moves will, eventually, return the cube to the same permutation from which it began; for example, one of the most fundamental sequences (aside from a Null/Identity move) is two half-turns of the same side. 14 By a solution-pair I mean, any pair of facelets that is oriented side-by-side when the cube is in its solved state. 15 This resulting Order heuristic proved to be significantly more reliable than the Minimum-Distance-Home. Its CV almost logarithmically shaped and asymptotic to approx. 40% when scrambled to 25 moves. 16 Named Dancing Facelets because it was inspired by a dream that thoroughly demonstrated the twisting, tangling and untangling of partner dancers\u2019 arms as they move in relation to one-another amidst a crowd of other dancers. This heuristic was even more reliable with respect to CV, never exceeding 25%.","title":"Home"},{"location":"#my-search-for-a-novel-algorithmic-solution-to-rubiks-cube","text":"This repository contains a collection of Python classes and notebooks for exploring algorithmic solutions to Rubik\u2019s cube. I began the project to experiment with Deep Reinforcement Learning, but I think my most interesting results came from abstracted notions of entropy and periodicity applied to the cube. I originally considered a sliding puzzle for the project, but then opted for Rubik\u2019s cube for some added challenge, which it certainly delivered. After six months of diligent effort, I am yet to develop a novel method that can fully crack it, not to mention that I often felt a sense that a solution was just around the corner, making the puzzle as fun as it was vexing. This article describes the solution strategies and results I've traversed thus far (chronologically, despite some arguably ill-conceived, hindsight is 20/20, directions). For discussion of the actual class implementations in the repository, especially those that represent and display the cube (i.e. models and views), please navigate to the Code Docs article.","title":"My Search for a Novel Algorithmic Solution to Rubik\u2019s Cube"},{"location":"#strategy-1-neural-networks-nn-and-deep-reinforcement-learning-drl","text":"For Demo see Notebook 2: Neural Networks My initial direction for solving the cube was to emulate a DRL strategy akin to that developed by DeepMind with its AlphaGo 1 program. This same essential strategy is also described by a group out of UC Irvine in their paper, Solving the Rubik\u2019s Cube Without Human Knowledge. 2 The strategy gist is to combine a NN with a Monte Carlo Tree Search (MCTS), with implementations varying in NN architecture, training methodology, specifics of tree expansion/rollout, etc. Though I eventually made extensive and (moderately) effective use of the tree search, I quickly realized that conventional DRL/RL is not ideally suited for Rubik\u2019s cube because it, RL, depends on initially random moves to produce enough successful outcomes for learning to begin. But unfortunately, a 3x3 cube has 43 quintillion (10^18) possible permutations and one solution. 3 Ever solving it with initially random moves is highly improbable to say the least. This led me to pursue training a NN independently, potentially to drop into DRL afterword, but primarily just to evaluate whether a viable statistical relationship between cube permutations and solution sequences could be established. To generate a training and validation dataset, I used the fact that a valid solution sequence to a cube can be obtained by simply reversing the moves used to scramble it, and if the scramble involves 20 or fewer (non-redundant) moves, one can also probably safely assume the solution is relatively efficient. 4 But despite experimenting with a variety of NN architectures and formats for NN input (for example calculating and using certain vector relationships between cube-facelets 5 as input rather than using straight facelet positions), I was unable to train a network that generalized beyond approx. 20% accuracy to a validation set (as depicted in graphs below). I could overfit training data to ~60% accuracy and suspected such network \u2018memorization\u2019 could continue with a large enough network, which, if inserted into DRL, could theoretically solve cubes whenever the tree-search found a memorized permutation. I\u2019m not clear whether learning could take hold from there, but regardless, I did not continue with that exploration 6 given my limiting computing power to train a very large network. Figure 1: The unfortunately dismal training results using Dance Heuristic inputs into a 5-layer, full-connected policy network","title":"Strategy #1: Neural Networks (NN) and Deep Reinforcement Learning (DRL)"},{"location":"#strategy-2-heuristic-guided-upper-confidence-bound-ucb-tree-search","text":"For Demo see Notebook 1: Intro-Cube-View My next effort was dedicated to honing a UCB tree search. 7 I began by developing a heuristic function I called Minimum-Distance-Home (see Figure 2 below). A characteristic of the cube is that any given facelet can, independently, be returned to its solved position in at most 2 moves if it is a corner facelet, or 3 moves if it is an edge. The overall heuristic then, is the sum over all facelets of this number-of-moves-to-solved (i.e. 0, 1, 2 or 3) for a given cube permutation. 8 On the positive side, I was fairly happy with the performance of my UCB tree search after optimizing my cube class representation to be based almost entirely on NumPy arrays and matrix operations. Still, the size of the search space was too much. Though I was usually able to solve cubes scrambled out 5-6 moves, beyond that the failure rates spiked. Figure 2: Still from Minimum-Distance-Home (MDH) animation (click to watch video ). Depicts the MDH heuristic as cubes are scrambled and solved/reverse-scrambled. The three rings of the target shaped diagram represent the number (0 to 3) of moves a facelet requires to return to its home/solved position (the center of the target representing home/solved) The 18 spokes represent possible cube moves (in Half-Turn-Metric, notated by face-color and rotation-angle) The small, colored, numbered circles represent the facelets themselves, and the thicker lines represent viable move sequences/trajectories each facelet could traverse to return home 9","title":"Strategy #2: Heuristic-Guided, Upper-Confidence-Bound (UCB) Tree Search"},{"location":"#strategy-3-fridrichs-cfop-human-speedcubing-algorithm","text":"For Demo see Notebook 3: CFOP Algorithm I focused my efforts next on integrating human-understanding/strategy into a machine-learning algorithm. 10 The most popular speedcubing method: CFOP, solves the cube in four, layer-based steps, specifically: 1) the Cross, 2) the First 2 Layers, 3) Orient the Last Layer, and 4) Permute the Last Layer. 11 Thus, an obvious approach seemed to be to develop a solver that mimicked a human speedcuber and then use it to generate a training dataset for each step. 12 There are approximately 80, explicitly defined move sequences for the final OLL and PLL steps; challenging for a human to memorize, but essentially trivial to apply in software. The Cross and F2L steps, however, are not as strictly defined, leading me to adapt my tree search to handle them. After a few weeks of work, I finally succeed in algorithmically solving my first cube! Unfortunately, even searching just through the F2L solution was surprisingly complex. Typically search trees would contain 5-15 million nodes, 40-45% of which would be visited. Searches would usually converge in 7-15 (at times up to 20) minutes to solutions that involved 50-70 moves, though some cubes would fail. The large convergence time required per cube thwarted my hopes of ever generating an adequately sized training dataset in a reasonable time frame. Furthermore, the code started to become fairly convoluted and the entire solving strategy piecemeal, in my opinion, as I added the many layers of human-like solving logic necessary to facilitate convergence. Figure 3: Example output of CFOP algorithm solving last few moves of an F2L stage","title":"Strategy #3: Fridrich\u2019s (CFOP) Human Speedcubing Algorithm"},{"location":"#strategy-4-entropy-sequence-periodicity-and-dancing-facelets","text":"For Demo see Notebook 4: Cycles and Entropy Unsatisfied with my piecemeal solution thus far and, coincidentally, studying the writings of theoretical physicist, David Bohm, particularly concerning distinctions between creative versus mechanistic modes, I began to develop some tangential experiments and visualizations of the cube. These included creating some atypical video animations of the cube as it was scrambled and then solved and examining a cube\u2019s fundamental periodic/repeatable move sequences. 13 Figure 4: Graph of rotational periods for the first 160 fundamental two-sided rotation sequences I noticed in an animation, in contrast to human strategies, highly efficient solutions rarely move facelets to their solved/home positions, right up until the last few moves, when suddenly the whole cube clicks together. This inspired me to create an \u201cEntropy/Order\u201d heuristic intended to measure a kind of entropy or level of order/disorder of a cube permutation. I awarded 1 point to any solution-pair of facelets 14 that achieved a side-by-side orientation, regardless of where that occurred on the overall surface of the cube, then summed this reward across all facelets. 15 As I worked to integrate these new ideas into my tree search, I was surprised to find almost by accident, a short segment of test code was nearly solving the cube by itself. It simply iterated through periodic move sequences and maximized the Order heuristic. I explored this direction further, developing a more sophisticated heuristic I called Dancing Facelets. 16 It could collapse to the Order heuristic if so configured or could measure more nuanced relationships between facelets such as angular measurements or triad relationships. I continued to explore methods of integrating these new components into my tree search or progress with them independently. And I continued to \u201cnearly\u201d solve the cube, but evidently appearances are deceiving with Rubik\u2019s cube; my attempts were clearly converging to local minimums and it wasn\u2019t entirely clear how close or far away true solutions remained. Thus, despite some intriguing results, I\u2019m still at least one more step from victory. Touch\u00e9, Mr. Rubik.","title":"Strategy #4: Entropy, Sequence Periodicity and Dancing Facelets"},{"location":"#footnotes","text":"1 See: https://deepmind.com/blog/article/alphago-zero-starting-scratch 2 See: https://arxiv.org/abs/1805.07470. Though the UC Irvine group arrived at a successful implementation and created an online simulator to demonstrate it (see: http://deepcube.igb.uci.edu/), to my knowledge, they have not released their code base and individuals who have tried to replicate their results thus far have been unsuccessful. 3 Despite the colossal size of the permutation space, the maximum possible moves necessary to solve a cube from any position, known as God\u2019s number, is only 20 moves using the Half-Turn-Metric (HTM, i.e. a 180-degree turn counted as one move), or 26 moves using the Quarter-Turn-Metric (QTM) (see: https://www.cube20.org/). Note this also implies that any possible cube permutation is theoretically reachable within a 20-move scramble. 4 From what I can ascertain, this is essentially what the UC Irvine group did as well, though their description is mathematically and pictorially complicated enough that I must admit some confusion in this regard. 5 I use the moniker: facelet, to indicate any of the 54 individual, colored squares that comprise the 3x3 cube, or more specifically the cube is comprised of 6 center facelets, 24 corner facelets, and 24 edge facelets. 6 This strategy seemed kind of like bastardizing a reduction algorithm (see: Thistlethwaite's Algorithm that permutes a cube through smaller, exhaustively searchable subgroups), and then hopefully leveraging that into learning with DRL. 7 Implemented essentially as a Monte Carlo Tree Search, minus the random (\u201cMonte Carlo\u201d) rollout step, removed largely due to the improbability of random moves ever achieving a solution state. 8 I eventually abandoned the Minimum-Distance-Home heuristic after recognizing that it becomes less reliable as a cube becomes more scrambled, w/coefficient of variation (CV) nearly 350% across cubes scrambled 25 moves. 9 Animation developed with Python open source package: Manim, developed by Grant Sanderson for his YouTube mathematics education channel. See: https://github.com/3b1b/manim 10 Driven by a desire to explore the third wave, Contextual Model Adaptation, of DARPA\u2019s Three-Wave theory of AI, specifically: 1) Handcrafted Knowledge, 2) Statistical Learning, 3) Context Adaptation. See: https://youtu.be/DARPA_AI_Perspective 11 For a more detailed description of CFOP, see: http://www.rubiksplace.com/speedcubing/guide/ 12 I knew getting this plan to generalize well may be tricky, having already established the cube\u2019s resistance to a typical NN training approach, nevertheless, I was essentially stumped and needed to turn some gears somehow. 13 Another interesting characteristic of Rubik\u2019s cube is its wave-like periodicity, meaning that any repetitive sequence of moves will, eventually, return the cube to the same permutation from which it began; for example, one of the most fundamental sequences (aside from a Null/Identity move) is two half-turns of the same side. 14 By a solution-pair I mean, any pair of facelets that is oriented side-by-side when the cube is in its solved state. 15 This resulting Order heuristic proved to be significantly more reliable than the Minimum-Distance-Home. Its CV almost logarithmically shaped and asymptotic to approx. 40% when scrambled to 25 moves. 16 Named Dancing Facelets because it was inspired by a dream that thoroughly demonstrated the twisting, tangling and untangling of partner dancers\u2019 arms as they move in relation to one-another amidst a crowd of other dancers. This heuristic was even more reliable with respect to CV, never exceeding 25%.","title":"Footnotes:"},{"location":"implementation/","text":"Exploring the Model's Code Implementation: For Full Source Code and Notebook Demos see GitHub Repo For the purposes of demonstration, the repository contains a set IPython/Jupyter Notebooks in the notebooks directory that walk through basic functionality and provide code samples for understanding and using the project\u2019s underlying classes. Classes are divided into Models (for cube representation, movement and display) and Solvers (for solution logic and supplements such tree node and solution state classes). These classes are located in the rubiks/model and rubiks/solver directories respectively. This doc provides specific descriptions of the model classes. For more detailed understanding of the solver classes, please refer to the notebook demonstrations and solver python files directly. Note that the repository also contains a rubiks/legacy directory and a sandbox directory, these are for historical storage and my working files only, they are not mantained or manicured for public use and are unnecessary for running notebooks or other classes in the repo. VectorCube.py: For Demo see Notebook 1: Intro-Cube-View To model the cube, I eventually chose to interpret it as a bona fide physical object in 3D space, by which I mean, each facelet has an actual 3D spatial position. Technically in the full cube matrix (i.e. the VectorCube field: facelet_matrix , a 5x54 NumPy array), each of the 54 facelets is a 5D column vector that holds a color-value 1 [WHITE_CB, ORANGE_CB, GREEN_CB, RED_CB, BLUE_CB, YELLOW_CB], a side-index [0,1,2,3,4,5,6,7 or 8], and the 3D spatial position-vector, with positional values from the set [-3,-2,-1,0,1,2, or 3]. The cube is defined with this size (i.e. 6x6) to assure that all 54 facelets can be defined with a unique spatial vector made entirely of integers that is closed (remains integers) under cube moves/rotations (i.e. positional vectors never suffer from accumulation of floating point error). Exectuting a (local) cube move/rotation is simply a function call: cube.rotate(move) . There are 18 possible moves (6-sides * 3-rotations [90, -90, or 180 degrees]). Underlying, these (local) rotations are specified as tuples: (color-value, rotation-angle), such as (WHITE_CB, 90). These move tuples map to actual 3x3 spatial rotation matrices that are applied to facelet positional vectors using matrix multiplication operations. Note that the center facelets of each side are positionally fixed (e.g. the WHITE center facelet is always at postion [0,0,3]), and thus the relationship of the sides are fixed; the WHITE side is always opposite the YELLOW side, etc. This is to say, the cube and (local) moves are defined relative to as fixed local coordinate system, which is oriented such that: GREEN and BLUE sides rotate about the x\u0302-axis RED and ORANGE sides rotate about the y\u0302-axis WHITE and YELLOW sides rotate about the z\u0302-axis Figure 1: LEFT: Dimensional depiction of the cube's WHITE side (9 facelets, all with color-value of WHITE_CB and side-index values shown). RIGHT: The default (and only) projection orientation (note that center facelets never moves). With the help of the diagram above, one can derive (for example, as the other sides are derived similarly) the nine 5D-vectors for the solved WHITE side as: Facelet Column Vector WHITE-facelet-0 [ 1 0 -2 -2 3] WHITE-facelet-1 [ 1 1 -2 0 3] WHITE-facelet-2 [ 1 2 -2 2 3] WHITE-facelet-3 [ 1 3 0 -2 3] WHITE-facelet-4 [ 1 4 0 0 3] WHITE-facelet-5 [ 1 5 0 2 3] WHITE-facelet-6 [ 1 6 2 -2 3] WHITE-facelet-7 [ 1 7 2 0 3] WHITE-facelet-8 [ 1 8 2 2 3] SMAdapter.py: For Demo see Notebook 1: Intro-Cube-View The generally accepted default notation for Rubik's cube moves is called Singmaster Notation. Using the SMAdapter class (which is implemented as essentially a VectorCube wrapper class) all Singmaster Notation moves can be applied to a VectorCube including full cube rotations, slice turns and double layer turns. These are applied as global rotations that can be mixed with local rotation moves. The full set of supported Singmaster notation is: Move Type Singmaster Notation Clockwise face rotations: [U, L, F, R, B, D, U2, L2, F2, R2, B2, D2] Counterclockwise face: [U', L', F', R', B', D'] Slice turns: [M, M', E, E', S, S', M2, E2, S2] Double layer turns: [u, l, f, r, b, d, u2, l2, f2, r2, b2, d2] Inverse double layer turns: [u', l', f', r', b', d'] Whole cube rotations: [X, X', Y, Y', Z, Z', X2, Y2, Z2] Figure 2: Singmaster move code snippet and output, including retrieval of corresponding local moves. Note that only 4 local moves are needed to represent this 7 SM move sequence corresponding_local_moves = [] some_singmaster_moves = ['Y2', 'F2', 'S2', \"Y'\", 'X2', 'z', \"B'\"] cube = VectorCube() cube_adpt = SMAdapter(cube) # Add a view for displaying view = CubeView(cube) view.push_snapshot(caption=\"Before\") for sm_move in some_singmaster_moves: cube_adpt.rotate_singmaster(sm_move, corresponding_local_moves) print(\"Local moves:\", [f'({color_letr(mv[0])}:{mv[1]})' for mv in corresponding_local_moves]) view.push_snapshot(caption=\"After\").draw_snapshots() Local moves: ['(B:180)', '(G:180)', '(B:180)', '(O:-90)'] CfopCube.py and DirectCube.py: For Demos see Notebooks 3 & 4: CFOP Algorithm & Cycles and Entropy From the standpoint of class structure, VectorCube is a cube base class. Both CfopCube and DirectCube derive from it, CfopCube containing additional fields for the CFOP solver, and DirectCube storing an additional set of directional vectors for each facelet to facilitate the Dancing Facelet heuristic. CubeView.py: For Demo see Notebook 1: Intro-Cube-View Finally, display of the cube is handled almost entirely by the CubeView class, which executes all displays using Matplotlib. It can display both 2D projections or 3D displays of the cube. Move sequences can be displayed as (gridded) series of 2D projections or as animated versions of the 3D display. Index filters can also be provided in some CubeView functions to limit which cube facelets get displayed in full color (or in 3D, if they\u2019re displayed at all). There a several pre-defined index arrays contained in VectorCube, or they may be created uniquely at runtime. The following snippet and output demonstrate use of index filtering: Figure 3: Example snippet and output using index color-filtering feature available CubeView class view = CubeView(VectorCube()) view.push_snapshot(flet_idx=VectorCube._centers) view.push_snapshot(flet_idx=VectorCube._order_cn_cnt) view.push_snapshot(flet_idx=VectorCube._order_ed_cnt) view.push_snapshot(flet_idx=VectorCube._order_cn_ed) view.push_snapshot(flet_idx=VectorCube._order_ed) view.draw_snapshots() Generating 3D animations can be accomplished simply by bounding any set of cube moves within calls to CubeView's record_moves function, and then invoking an IPython.display HTML translation (please see notebooks for example animations): # Begin recording view.record_moves() # Any set of cube moves/rotations and other code here # Stop recording view.record_moves(stop_recording=True) # Tranlate to HTML and display in notebook HTML(view.get_animation_3d().to_jshtml()) Footnotes: 1 VectorCube defines a set of color-value constants: # COLORS/SIDES: WHITE_CB, W = 1, 1 ORANGE_CB, O = 2, 2 GREEN_CB, G = 3, 3 RED_CB, R = 4, 4 BLUE_CB, B = 5, 5 YELLOW_CB, Y = 6, 6","title":"Code Docs"},{"location":"implementation/#exploring-the-models-code-implementation","text":"For Full Source Code and Notebook Demos see GitHub Repo For the purposes of demonstration, the repository contains a set IPython/Jupyter Notebooks in the notebooks directory that walk through basic functionality and provide code samples for understanding and using the project\u2019s underlying classes. Classes are divided into Models (for cube representation, movement and display) and Solvers (for solution logic and supplements such tree node and solution state classes). These classes are located in the rubiks/model and rubiks/solver directories respectively. This doc provides specific descriptions of the model classes. For more detailed understanding of the solver classes, please refer to the notebook demonstrations and solver python files directly. Note that the repository also contains a rubiks/legacy directory and a sandbox directory, these are for historical storage and my working files only, they are not mantained or manicured for public use and are unnecessary for running notebooks or other classes in the repo.","title":"Exploring the Model's Code Implementation:"},{"location":"implementation/#vectorcubepy","text":"For Demo see Notebook 1: Intro-Cube-View To model the cube, I eventually chose to interpret it as a bona fide physical object in 3D space, by which I mean, each facelet has an actual 3D spatial position. Technically in the full cube matrix (i.e. the VectorCube field: facelet_matrix , a 5x54 NumPy array), each of the 54 facelets is a 5D column vector that holds a color-value 1 [WHITE_CB, ORANGE_CB, GREEN_CB, RED_CB, BLUE_CB, YELLOW_CB], a side-index [0,1,2,3,4,5,6,7 or 8], and the 3D spatial position-vector, with positional values from the set [-3,-2,-1,0,1,2, or 3]. The cube is defined with this size (i.e. 6x6) to assure that all 54 facelets can be defined with a unique spatial vector made entirely of integers that is closed (remains integers) under cube moves/rotations (i.e. positional vectors never suffer from accumulation of floating point error). Exectuting a (local) cube move/rotation is simply a function call: cube.rotate(move) . There are 18 possible moves (6-sides * 3-rotations [90, -90, or 180 degrees]). Underlying, these (local) rotations are specified as tuples: (color-value, rotation-angle), such as (WHITE_CB, 90). These move tuples map to actual 3x3 spatial rotation matrices that are applied to facelet positional vectors using matrix multiplication operations. Note that the center facelets of each side are positionally fixed (e.g. the WHITE center facelet is always at postion [0,0,3]), and thus the relationship of the sides are fixed; the WHITE side is always opposite the YELLOW side, etc. This is to say, the cube and (local) moves are defined relative to as fixed local coordinate system, which is oriented such that: GREEN and BLUE sides rotate about the x\u0302-axis RED and ORANGE sides rotate about the y\u0302-axis WHITE and YELLOW sides rotate about the z\u0302-axis Figure 1: LEFT: Dimensional depiction of the cube's WHITE side (9 facelets, all with color-value of WHITE_CB and side-index values shown). RIGHT: The default (and only) projection orientation (note that center facelets never moves). With the help of the diagram above, one can derive (for example, as the other sides are derived similarly) the nine 5D-vectors for the solved WHITE side as: Facelet Column Vector WHITE-facelet-0 [ 1 0 -2 -2 3] WHITE-facelet-1 [ 1 1 -2 0 3] WHITE-facelet-2 [ 1 2 -2 2 3] WHITE-facelet-3 [ 1 3 0 -2 3] WHITE-facelet-4 [ 1 4 0 0 3] WHITE-facelet-5 [ 1 5 0 2 3] WHITE-facelet-6 [ 1 6 2 -2 3] WHITE-facelet-7 [ 1 7 2 0 3] WHITE-facelet-8 [ 1 8 2 2 3]","title":"VectorCube.py:"},{"location":"implementation/#smadapterpy","text":"For Demo see Notebook 1: Intro-Cube-View The generally accepted default notation for Rubik's cube moves is called Singmaster Notation. Using the SMAdapter class (which is implemented as essentially a VectorCube wrapper class) all Singmaster Notation moves can be applied to a VectorCube including full cube rotations, slice turns and double layer turns. These are applied as global rotations that can be mixed with local rotation moves. The full set of supported Singmaster notation is: Move Type Singmaster Notation Clockwise face rotations: [U, L, F, R, B, D, U2, L2, F2, R2, B2, D2] Counterclockwise face: [U', L', F', R', B', D'] Slice turns: [M, M', E, E', S, S', M2, E2, S2] Double layer turns: [u, l, f, r, b, d, u2, l2, f2, r2, b2, d2] Inverse double layer turns: [u', l', f', r', b', d'] Whole cube rotations: [X, X', Y, Y', Z, Z', X2, Y2, Z2] Figure 2: Singmaster move code snippet and output, including retrieval of corresponding local moves. Note that only 4 local moves are needed to represent this 7 SM move sequence corresponding_local_moves = [] some_singmaster_moves = ['Y2', 'F2', 'S2', \"Y'\", 'X2', 'z', \"B'\"] cube = VectorCube() cube_adpt = SMAdapter(cube) # Add a view for displaying view = CubeView(cube) view.push_snapshot(caption=\"Before\") for sm_move in some_singmaster_moves: cube_adpt.rotate_singmaster(sm_move, corresponding_local_moves) print(\"Local moves:\", [f'({color_letr(mv[0])}:{mv[1]})' for mv in corresponding_local_moves]) view.push_snapshot(caption=\"After\").draw_snapshots() Local moves: ['(B:180)', '(G:180)', '(B:180)', '(O:-90)']","title":"SMAdapter.py:"},{"location":"implementation/#cfopcubepy-and-directcubepy","text":"For Demos see Notebooks 3 & 4: CFOP Algorithm & Cycles and Entropy From the standpoint of class structure, VectorCube is a cube base class. Both CfopCube and DirectCube derive from it, CfopCube containing additional fields for the CFOP solver, and DirectCube storing an additional set of directional vectors for each facelet to facilitate the Dancing Facelet heuristic.","title":"CfopCube.py and DirectCube.py:"},{"location":"implementation/#cubeviewpy","text":"For Demo see Notebook 1: Intro-Cube-View Finally, display of the cube is handled almost entirely by the CubeView class, which executes all displays using Matplotlib. It can display both 2D projections or 3D displays of the cube. Move sequences can be displayed as (gridded) series of 2D projections or as animated versions of the 3D display. Index filters can also be provided in some CubeView functions to limit which cube facelets get displayed in full color (or in 3D, if they\u2019re displayed at all). There a several pre-defined index arrays contained in VectorCube, or they may be created uniquely at runtime. The following snippet and output demonstrate use of index filtering: Figure 3: Example snippet and output using index color-filtering feature available CubeView class view = CubeView(VectorCube()) view.push_snapshot(flet_idx=VectorCube._centers) view.push_snapshot(flet_idx=VectorCube._order_cn_cnt) view.push_snapshot(flet_idx=VectorCube._order_ed_cnt) view.push_snapshot(flet_idx=VectorCube._order_cn_ed) view.push_snapshot(flet_idx=VectorCube._order_ed) view.draw_snapshots() Generating 3D animations can be accomplished simply by bounding any set of cube moves within calls to CubeView's record_moves function, and then invoking an IPython.display HTML translation (please see notebooks for example animations): # Begin recording view.record_moves() # Any set of cube moves/rotations and other code here # Stop recording view.record_moves(stop_recording=True) # Tranlate to HTML and display in notebook HTML(view.get_animation_3d().to_jshtml())","title":"CubeView.py:"},{"location":"implementation/#footnotes","text":"1 VectorCube defines a set of color-value constants: # COLORS/SIDES: WHITE_CB, W = 1, 1 ORANGE_CB, O = 2, 2 GREEN_CB, G = 3, 3 RED_CB, R = 4, 4 BLUE_CB, B = 5, 5 YELLOW_CB, Y = 6, 6","title":"Footnotes:"},{"location":"quickstart/","text":"Project: rubiks-cube This project is a collection of Python classes developed to explore algorithmic solutions to Rubik's Cube. The repository contains a set of notebooks to walk interested parties through my progress with the puzzle thus far, and highlight some features of the classes for modeling and displaying the cube contained herein. For a preliminary and complete explanation of my solution strategies thus far, please peruse the blog article referenced above. Installation The repository is setup for pipenv configuration management, thus you'll find a Pipfile rather than requirements.txt file. You may access installation instructions for pipenv here: Pipenv Installation Instructions Once pipenv has been successfully installed, the following commands may be executes to install the rubiks-cube project: git clone https://github.com/ajdonich/rubiks-cube cd rubik-cube pipenv install pipenv --dev install Execution To understand the specifics of this project, please step through the interactive set of IPython/Jupyter notebooks provided. First, launch a notebook session from the command line using: pipenv shell jupyter lab Then from within the notebook session that is launched in your browser, navigate to the notebooks directory. This directory contains this set of demo notbook: Intro Cube View Neural Networks CFOP Algorithm Cycles Entropy Please step through these files, titled numerical with the suggested running order. Execute each cell of each notebook in turn, exploring the code execution output. You'll also find a number of markdown cells with further descriptive details. I hope you find the demonstrations interesting and enjoyable!","title":"Quick Start"},{"location":"quickstart/#project-rubiks-cube","text":"This project is a collection of Python classes developed to explore algorithmic solutions to Rubik's Cube. The repository contains a set of notebooks to walk interested parties through my progress with the puzzle thus far, and highlight some features of the classes for modeling and displaying the cube contained herein. For a preliminary and complete explanation of my solution strategies thus far, please peruse the blog article referenced above.","title":"Project: rubiks-cube"},{"location":"quickstart/#installation","text":"The repository is setup for pipenv configuration management, thus you'll find a Pipfile rather than requirements.txt file. You may access installation instructions for pipenv here: Pipenv Installation Instructions Once pipenv has been successfully installed, the following commands may be executes to install the rubiks-cube project: git clone https://github.com/ajdonich/rubiks-cube cd rubik-cube pipenv install pipenv --dev install","title":"Installation"},{"location":"quickstart/#execution","text":"To understand the specifics of this project, please step through the interactive set of IPython/Jupyter notebooks provided. First, launch a notebook session from the command line using: pipenv shell jupyter lab Then from within the notebook session that is launched in your browser, navigate to the notebooks directory. This directory contains this set of demo notbook: Intro Cube View Neural Networks CFOP Algorithm Cycles Entropy Please step through these files, titled numerical with the suggested running order. Execute each cell of each notebook in turn, exploring the code execution output. You'll also find a number of markdown cells with further descriptive details. I hope you find the demonstrations interesting and enjoyable!","title":"Execution"}]}